{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d45b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SequenceDeltaAlgo.ipynb\n",
    "%run SentimentAnalysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants ------------------------------------------------------------------------------\n",
    "# fed url\n",
    "DAY_FS='[YYYYMMDD]'\n",
    "FS_HOST= 'https://www.federalreserve.gov'\n",
    "URL_FS= 'https://www.federalreserve.gov/newsevents/pressreleases/monetary[YYYYMMDD]a.htm'\n",
    "URL_CALENDAR = 'https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm'\n",
    "\n",
    "global lastFSD\n",
    "\n",
    "\n",
    "# Methods scraping and feed ---------------------------------------------------------------\n",
    "\n",
    "def get_links():\n",
    "    r = requests.get(URL_CALENDAR)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    contents = soup.find_all('a', href=re.compile('^/newsevents/pressreleases/monetary\\d{8}[ax].htm'))\n",
    "    links = [FS_HOST + content.attrs['href'] for content in contents]\n",
    "    fomc = {}\n",
    "    for link in links:\n",
    "        strDate = re.findall('[0-9]{8}', link)[0]\n",
    "        fomc[strDate] = link\n",
    "    return fomc\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def strLoadArticle(strdate, url=None):\n",
    "    datedArticle = 'fedStates/'+ strdate\n",
    "    if os.path.exists(datedArticle):\n",
    "        return datedArticle\n",
    "    else:\n",
    "        datedUrl = URL_FS.replace(DAY_FS, strdate) if url is None else url\n",
    "        try:\n",
    "            page = requests.get(datedUrl)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            divs =  soup.find(id=\"article\").findAll('div')\n",
    "            ldivs = list(map(lambda d: len(d.findChildren(\"p\", recursive=False)), divs))\n",
    "            articleDiv = divs[ldivs.index(max(ldivs))]\n",
    "            ps = articleDiv.findAll('p')\n",
    "            \n",
    "            for tag in articleDiv.findAll(True):\n",
    "                if len(tag.attrs)> 0 :\n",
    "                    tag.attrs = {}\n",
    "                    content = list(map(lambda p: str(p), ps))\n",
    "            with open(datedArticle, \"w\") as f:\n",
    "                sad = str(\" <br> \".join(content))\n",
    "                sad += createSimpleNLP(sad, datedUrl, strdate)\n",
    "                f.write(sad)\n",
    "                \n",
    "            return datedArticle \n",
    "        except:\n",
    "            traceback.format_exc()\n",
    "            return None\n",
    "        \n",
    "  \n",
    "    \n",
    "def extractArticle(sdate):\n",
    "    datedArticle = strLoadArticle(sdate)\n",
    "    if not datedArticle is None:\n",
    "        with open(datedArticle, 'r') as f:\n",
    "             content = f.read()\n",
    "        return content\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "def splitArticle(a):\n",
    "    a = a.replace('<p>', '')\n",
    "    a = a.replace('</p>', '')\n",
    "    np = a.rfind('<div id=\"snlp\"')\n",
    "    content = filter(lambda w: w.strip() != '', a[0:np].split(' ')) \n",
    "    wordProxies = list(map(lambda w: WordProxy(w), content))\n",
    "    score =  a[np:]\n",
    "    return wordProxies, score \n",
    " \n",
    "    \n",
    "def startupArticles():\n",
    "    global lastFSD \n",
    "    lastFSD = None\n",
    "    fomc = get_links()\n",
    "    \n",
    "    dateRegex = re.compile(r'(\\d{8})')\n",
    "    for datedFile in os.listdir('fedStates/'):\n",
    "        if dateRegex.search(datedFile):\n",
    "            fomc.pop(datedFile)\n",
    "            if lastFSD is None:\n",
    "                lastFSD = datedFile\n",
    "            elif lastFSD < datedFile:\n",
    "                lastFSD = datedFile\n",
    "    \n",
    "    for d, url in sorted(fomc.items()):\n",
    "        if not strLoadArticle(d, url) is None:\n",
    "            lastFSD = d\n",
    "\n",
    "\n",
    "        \n",
    "def dailyCheckArticle():\n",
    "    global lastFSD\n",
    "    sdnow = datetime.now().strftime(\"%Y%m%d\")\n",
    "    if lastFSD < sdnow:\n",
    "        if not strLoadArticle(sdnow) is None:\n",
    "            lastFSD = sdnow\n",
    "            generateNLPGraph()\n",
    "            return lastFSD\n",
    "    return None\n",
    "\n",
    "\n",
    "def createSimpleNLP(sad, url, d): \n",
    "    nlpBloc = \"\"\"\n",
    "                <br>\n",
    "                <div id=\"snlp\" style=\"background-color:#FCF3CF;\"> \n",
    "                    <h3>Sentiment Analysis for Fed Statment date: <a href='[url]'>[date]</h3>\n",
    "                    <h4><span style=\"color:blue\">Net       : [=]</span></h4>\n",
    "                    <h4><span style=\"color:green\">Positive  : [+]</span></h4>\n",
    "                    <h4><span style=\"color:red\">Negative  : [-]</span></h4>\n",
    "                  \n",
    "                 </div>\n",
    "              \"\"\"\n",
    "    nlpBloc = nlpBloc.replace('[url]', url)\n",
    "    nlpBloc = nlpBloc.replace('[date]', d)\n",
    "    \n",
    "    pscore = calculateNLP(sad)\n",
    "    nlpBloc = nlpBloc.replace('[=]', str(round(pscore[\"net\"],6)))\n",
    "    nlpBloc = nlpBloc.replace('[+]', str(round(pscore[\"pos\"],6)))\n",
    "    nlpBloc = nlpBloc.replace('[-]', str(round(pscore[\"neg\"],6)))\n",
    "    \n",
    "    return nlpBloc\n",
    "\n",
    "\n",
    "\n",
    "def parseSimpleNLP(nlpBloc):\n",
    "    strScore = []\n",
    "    for h4Bloc in nlpBloc.split('</h4>')[:-1] :\n",
    "        strScore.append(h4Bloc.split('</span>')[1]) \n",
    "    return strScore\n",
    "\n",
    "\n",
    "def createDeltaNLP(fix, new, old, sda0, sda1, nlpScore0, nlpScore1): \n",
    "    dNlpBloc = \"\"\"\n",
    "                <br>\n",
    "                <div id=\"deltaNlp\" style=\"background-color:#FCF3CF;\"> \n",
    "                    <h3>Sentiment Analysis for Fed Statment Delta:</h3>\n",
    "                    <table style=\"font-size:20px;width: 70%;\">\n",
    "                        <tr style=\"background-color:#DCDCDC;\">\n",
    "                          <th style=\"text-align: left;width: 19%;border-bottom: thin solid;\"></th>\n",
    "                          <th style=\"text-align: left;width: 18%;border-bottom: thin solid;\"><span style=\"background-color:#ff6424;\">[d0]</span></th>\n",
    "                          <th style=\"text-align: left;width: 18%;border-bottom: thin solid;\"><span style=\"background-color:lightgreen\">[d1]</span></th>\n",
    "                          <th style=\"text-align: left;width: 15%;border-bottom: thin solid;\">Common items</th>\n",
    "                          <th style=\"text-align: left;width: 15%;border-bottom: thin solid;color:red\">Deleted items</th>\n",
    "                          <th style=\"text-align: left;width: 15%;border-bottom: thin solid;color:green;\">New items</th>\n",
    "                        </tr>\n",
    "                        <tr style=\"color:blue\">\n",
    "                          <td style=\"border-bottom: thin solid;\">Net</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[so=]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[sn=]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[f=]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[o=]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[n=]</td>\n",
    "                        </tr>\n",
    "                        <tr style=\"color:green\">\n",
    "                          <td style=\"border-bottom: thin solid;\">Positive</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[so+]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[sn+]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[f+]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[o+]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[n+]</td>\n",
    "                        </tr>\n",
    "                        <tr style=\"color:red\">\n",
    "                          <td style=\"border-bottom: thin solid;\">Negative</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[so-]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[sn-]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[f-]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[o-]</td>\n",
    "                          <td style=\"border-bottom: thin solid;\">[n-]</td>\n",
    "                        </tr>\n",
    "                      </table>\n",
    "                 </div>\n",
    "              \"\"\"\n",
    "    dNlpBloc = dNlpBloc.replace('[d0]', sda0)\n",
    "    dNlpBloc = dNlpBloc.replace('[d1]', sda1)\n",
    "    \n",
    "\n",
    "    dNlpBloc = dNlpBloc.replace('[so=]', nlpScore0[0])\n",
    "    dNlpBloc = dNlpBloc.replace('[so+]', nlpScore0[1])\n",
    "    dNlpBloc = dNlpBloc.replace('[so-]', nlpScore0[2])\n",
    "    \n",
    "    dNlpBloc = dNlpBloc.replace('[sn=]', nlpScore1[0])\n",
    "    dNlpBloc = dNlpBloc.replace('[sn+]', nlpScore1[1])\n",
    "    dNlpBloc = dNlpBloc.replace('[sn-]', nlpScore1[2])\n",
    "    \n",
    "    fixscore = calculateNLP(fix)\n",
    "    dNlpBloc = dNlpBloc.replace('[f=]', str(round(fixscore[\"net\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[f+]', str(round(fixscore[\"pos\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[f-]', str(round(fixscore[\"neg\"],6)))\n",
    "    \n",
    "    newscore = calculateNLP(new)\n",
    "    dNlpBloc = dNlpBloc.replace('[n=]', str(round(newscore[\"net\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[n+]', str(round(newscore[\"pos\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[n-]', str(round(newscore[\"neg\"],6)))\n",
    "    \n",
    "    oldscore = calculateNLP(old)\n",
    "    dNlpBloc = dNlpBloc.replace('[o=]', str(round(oldscore[\"net\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[o+]', str(round(oldscore[\"pos\"],6)))\n",
    "    dNlpBloc = dNlpBloc.replace('[o-]', str(round(oldscore[\"neg\"],6)))\n",
    "    \n",
    "    return dNlpBloc\n",
    "\n",
    "\n",
    "def calculateDeltaArticles(sdate0, sdate1):\n",
    "    a0 =  extractArticle(sdate0)\n",
    "    a1 =  extractArticle(sdate1)\n",
    "    wordproxies0, nlp0 = splitArticle(a0)\n",
    "    wordproxies1, nlp1 = splitArticle(a1)\n",
    "    nlpScore0 = parseSimpleNLP(nlp0)\n",
    "    nlpScore1 = parseSimpleNLP(nlp1)\n",
    "    res, fix, new, old = processSequences(wordproxies1, wordproxies0)\n",
    "    dNlpBloc = createDeltaNLP(fix, new, old, sdate0, sdate1, nlpScore0, nlpScore1)\n",
    "    return res + '<br>' + dNlpBloc\n",
    "\n",
    "\n",
    "def generateNLPGraph():\n",
    "    # initialize list of lists\n",
    "    tsScore = []\n",
    "    dateRegex = re.compile(r'(\\d{8})')\n",
    "    for datedFile in os.listdir('fedStates/'):\n",
    "        if dateRegex.search(datedFile):\n",
    "            a =  extractArticle(datedFile)\n",
    "            w, nlp = splitArticle(a)\n",
    "            score = [datedFile[0:4] + '-' + datedFile[4:6] + '-' + datedFile[6:8] , float(parseSimpleNLP(nlp)[0])] \n",
    "            tsScore.append(score)\n",
    "    colors = ['green']\n",
    "    df = pd.DataFrame(tsScore, columns =['Date', 'Net'])\n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df['Change'] = (df['Net'].shift(1) / df['Net'])\n",
    "    \n",
    "    #TODO smooting curve\n",
    "    \n",
    "    df = df.melt('Date', var_name='NLP',  value_name='score')\n",
    "    \n",
    "    sns.set_palette(sns.color_palette(colors))\n",
    "    sns_plot = sns.factorplot(x=\"Date\", y=\"score\", hue='NLP', data=df).set(title='Change in sentiment over time (first derivative)')\n",
    "    sns_plot.set_xticklabels(rotation=45) \n",
    "    sns_plot.fig.set_figwidth(24)\n",
    "    sns_plot.fig.set_figheight(8)\n",
    "    sns_plot.savefig(\"./static/historicNlp.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generateNLPGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2eae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d32548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
